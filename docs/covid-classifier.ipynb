{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "direct-trick",
   "metadata": {
    "papermill": {
     "duration": 0.013164,
     "end_time": "2021-04-23T16:58:47.511468",
     "exception": false,
     "start_time": "2021-04-23T16:58:47.498304",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "arctic-george",
   "metadata": {
    "papermill": {
     "duration": 0.01177,
     "end_time": "2021-04-23T16:58:47.535739",
     "exception": false,
     "start_time": "2021-04-23T16:58:47.523969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Build a classifier to predict whether a person is suffering from covid, cold, flu or allergy?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-music",
   "metadata": {
    "papermill": {
     "duration": 0.011886,
     "end_time": "2021-04-23T16:58:47.560069",
     "exception": false,
     "start_time": "2021-04-23T16:58:47.548183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**import the required packages and libraries**\n",
    "\n",
    "\n",
    "1.   Pandas is a Python library. Pandas is used to analyze data.\n",
    "2.   sklearn is a machine learning library for Python. It has classes and functions with respect to various algorithms like support vector machine, logistic regression, random forests, etc.\n",
    "\n",
    "  a. Label Encoder is for converting the values in the given column into numeric form \n",
    "\n",
    "  b.  StandardScaler will transform your data such that its distribution will have a mean value 0 and standard deviation of 1.\n",
    "\n",
    "  c. sklearn.metrics module implements functions assessing prediction error for specific purposes.\n",
    "\n",
    "  d.  train_test_split is a function in Sklearn model selection for splitting data arrays into two subsets: for training data and for testing data\n",
    "  \n",
    "5.   Keras is a Python library for neural networks\n",
    "\n",
    "6. joblib provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aggressive-argentina",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:58:47.598495Z",
     "iopub.status.busy": "2021-04-23T16:58:47.597656Z",
     "iopub.status.idle": "2021-04-23T16:58:55.057900Z",
     "shell.execute_reply": "2021-04-23T16:58:55.056750Z"
    },
    "papermill": {
     "duration": 7.485854,
     "end_time": "2021-04-23T16:58:55.058076",
     "exception": false,
     "start_time": "2021-04-23T16:58:47.572222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "import keras\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-decade",
   "metadata": {
    "papermill": {
     "duration": 0.012684,
     "end_time": "2021-04-23T16:58:55.083502",
     "exception": false,
     "start_time": "2021-04-23T16:58:55.070818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "**Data Preprocessing**\n",
    "1. read the dataset file\n",
    "2. do a little preprocessing to convert alphanumerical values in certain columns to numerical/ordinal values\n",
    "3. split the dataset into test and training datasets\n",
    "4. perform feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "drawn-journalist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:58:55.117744Z",
     "iopub.status.busy": "2021-04-23T16:58:55.117045Z",
     "iopub.status.idle": "2021-04-23T16:58:55.120476Z",
     "shell.execute_reply": "2021-04-23T16:58:55.119970Z"
    },
    "papermill": {
     "duration": 0.024604,
     "end_time": "2021-04-23T16:58:55.120631",
     "exception": false,
     "start_time": "2021-04-23T16:58:55.096027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readDataMulti():\n",
    "#add the csv file to the current directory before proceeding\n",
    "# read the CSV file\n",
    "  global scaler\n",
    "  global dictionary\n",
    "  global colnames\n",
    "   #path to the file in the current directory\n",
    "  features = pd.read_csv('/kaggle/input/covid-flu-cold-symptoms/large_data.csv')                            #reading the file\n",
    "  features = features.rename(columns={'TYPE' : 'class'})  #renaming the result column\n",
    "  colnames=features.columns\n",
    "  # Label Encoding refers to converting the labels into numeric form so as to convert it \n",
    "  # into the machine-readable form. \n",
    "  # Machine learning algorithms can then decide in a better way on how those labels must be operated\n",
    "  label_encoder = LabelEncoder()                               \n",
    "  features['class']= label_encoder.fit_transform(features['class']) #performing label encoding in the given column\n",
    "  labels = features.pop('class')  #removing the class column from the features table\n",
    "  keys = label_encoder.classes_  \n",
    "  values = label_encoder.transform(label_encoder.classes_)\n",
    "  dictionary = dict(zip(keys, values)) #storing the converted column entries as (key,value) pairs\n",
    "  print(dictionary)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.20,random_state=5)  #splitting the dataset into train and test set\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train = scaler.transform(X_train) \n",
    "  X_test = scaler.transform(X_test)\n",
    "  return X_train,y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-continent",
   "metadata": {
    "papermill": {
     "duration": 0.012107,
     "end_time": "2021-04-23T16:58:55.145244",
     "exception": false,
     "start_time": "2021-04-23T16:58:55.133137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building a neural network classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-celebration",
   "metadata": {
    "papermill": {
     "duration": 0.012747,
     "end_time": "2021-04-23T16:58:55.170407",
     "exception": false,
     "start_time": "2021-04-23T16:58:55.157660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Machine learning algorithms that use neural networks generally do not need to be programmed with specific rules that define what to expect from the input. The neural net learning algorithm instead learns from processing many labeled examples that are supplied during training and using this answer key to learn what characteristics of the input are needed to construct the correct output. Once a sufficient number of examples have been processed, the neural network can begin to process new, unseen inputs and successfully return accurate results.   \n",
    "\n",
    "Here we build a neural network classifier with 2 layers having 32 neurons each.\n",
    "1. Use tanh activation function for hidden layers\n",
    "2. Use softmax activation function for output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driving-diabetes",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:58:55.198641Z",
     "iopub.status.busy": "2021-04-23T16:58:55.197952Z",
     "iopub.status.idle": "2021-04-23T17:01:09.698698Z",
     "shell.execute_reply": "2021-04-23T17:01:09.699254Z"
    },
    "papermill": {
     "duration": 134.516625,
     "end_time": "2021-04-23T17:01:09.699457",
     "exception": false,
     "start_time": "2021-04-23T16:58:55.182832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALLERGY': 0, 'COLD': 1, 'COVID': 2, 'FLU': 3}\n",
      "Epoch 1/100\n",
      "1112/1112 [==============================] - 2s 1ms/step - loss: 0.3349 - accuracy: 0.8768\n",
      "Epoch 2/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.9328\n",
      "Epoch 3/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1081 - accuracy: 0.9302\n",
      "Epoch 4/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.9307\n",
      "Epoch 5/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.9333\n",
      "Epoch 6/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1037 - accuracy: 0.9352\n",
      "Epoch 7/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1059 - accuracy: 0.9304\n",
      "Epoch 8/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9324\n",
      "Epoch 9/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1028 - accuracy: 0.9331\n",
      "Epoch 10/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9359\n",
      "Epoch 11/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1048 - accuracy: 0.9323\n",
      "Epoch 12/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1023 - accuracy: 0.9346\n",
      "Epoch 13/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0987 - accuracy: 0.9366\n",
      "Epoch 14/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9322\n",
      "Epoch 15/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1010 - accuracy: 0.9329\n",
      "Epoch 16/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1012 - accuracy: 0.9331\n",
      "Epoch 17/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9329\n",
      "Epoch 18/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1006 - accuracy: 0.9330\n",
      "Epoch 19/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1008 - accuracy: 0.9343\n",
      "Epoch 20/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.9339\n",
      "Epoch 21/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1020 - accuracy: 0.9351\n",
      "Epoch 22/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1017 - accuracy: 0.9318\n",
      "Epoch 23/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1015 - accuracy: 0.9324\n",
      "Epoch 24/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1009 - accuracy: 0.9345\n",
      "Epoch 25/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.9340\n",
      "Epoch 26/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9345\n",
      "Epoch 27/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0992 - accuracy: 0.9347\n",
      "Epoch 28/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1028 - accuracy: 0.9315\n",
      "Epoch 29/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1025 - accuracy: 0.9327\n",
      "Epoch 30/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9349\n",
      "Epoch 31/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9360\n",
      "Epoch 32/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9305\n",
      "Epoch 33/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1010 - accuracy: 0.9337\n",
      "Epoch 34/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9353\n",
      "Epoch 35/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0992 - accuracy: 0.9331\n",
      "Epoch 36/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9354\n",
      "Epoch 37/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1015 - accuracy: 0.9330\n",
      "Epoch 38/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0998 - accuracy: 0.9339\n",
      "Epoch 39/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0968 - accuracy: 0.9359\n",
      "Epoch 40/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9349\n",
      "Epoch 41/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9348\n",
      "Epoch 42/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0968 - accuracy: 0.9357\n",
      "Epoch 43/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1018 - accuracy: 0.9327\n",
      "Epoch 44/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0992 - accuracy: 0.9366\n",
      "Epoch 45/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9355\n",
      "Epoch 46/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0983 - accuracy: 0.9366\n",
      "Epoch 47/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0994 - accuracy: 0.9335\n",
      "Epoch 48/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0974 - accuracy: 0.9353\n",
      "Epoch 49/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1008 - accuracy: 0.9324\n",
      "Epoch 50/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0971 - accuracy: 0.9354\n",
      "Epoch 51/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9339\n",
      "Epoch 52/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9351\n",
      "Epoch 53/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9377\n",
      "Epoch 54/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0986 - accuracy: 0.9345\n",
      "Epoch 55/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0965 - accuracy: 0.9350\n",
      "Epoch 56/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9339\n",
      "Epoch 57/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0983 - accuracy: 0.9348\n",
      "Epoch 58/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9362\n",
      "Epoch 59/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1001 - accuracy: 0.9338\n",
      "Epoch 60/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0968 - accuracy: 0.9372\n",
      "Epoch 61/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0987 - accuracy: 0.9337\n",
      "Epoch 62/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9341\n",
      "Epoch 63/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9347\n",
      "Epoch 64/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9358\n",
      "Epoch 65/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9359\n",
      "Epoch 66/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.9347\n",
      "Epoch 67/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9359\n",
      "Epoch 68/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9354\n",
      "Epoch 69/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1010 - accuracy: 0.9316\n",
      "Epoch 70/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9355\n",
      "Epoch 71/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9365\n",
      "Epoch 72/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9356\n",
      "Epoch 73/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0966 - accuracy: 0.9367\n",
      "Epoch 74/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1006 - accuracy: 0.9324\n",
      "Epoch 75/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9330\n",
      "Epoch 76/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9332\n",
      "Epoch 77/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9372\n",
      "Epoch 78/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9367\n",
      "Epoch 79/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0983 - accuracy: 0.9353\n",
      "Epoch 80/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9359\n",
      "Epoch 81/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9360\n",
      "Epoch 82/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9344\n",
      "Epoch 83/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0987 - accuracy: 0.9345\n",
      "Epoch 84/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9357\n",
      "Epoch 85/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9361\n",
      "Epoch 86/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0949 - accuracy: 0.9382\n",
      "Epoch 87/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.1000 - accuracy: 0.9328\n",
      "Epoch 88/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0969 - accuracy: 0.9372\n",
      "Epoch 89/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9377\n",
      "Epoch 90/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9378\n",
      "Epoch 91/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0993 - accuracy: 0.9334\n",
      "Epoch 92/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9375\n",
      "Epoch 93/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0953 - accuracy: 0.9380\n",
      "Epoch 94/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0945 - accuracy: 0.9373\n",
      "Epoch 95/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0992 - accuracy: 0.9359\n",
      "Epoch 96/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9356\n",
      "Epoch 97/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0943 - accuracy: 0.9372\n",
      "Epoch 98/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9368\n",
      "Epoch 99/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9380\n",
      "Epoch 100/100\n",
      "1112/1112 [==============================] - 1s 1ms/step - loss: 0.0947 - accuracy: 0.9372\n",
      "\n",
      "-- Training data --\n",
      "Accuracy: 93.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     13043\n",
      "           1       0.64      0.65      0.64       813\n",
      "           2       0.52      0.88      0.65      1638\n",
      "           3       0.98      0.93      0.95     20068\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     35562\n",
      "   macro avg       0.78      0.86      0.81     35562\n",
      "weighted avg       0.95      0.94      0.94     35562\n",
      " samples avg       0.94      0.94      0.94     35562\n",
      "\n",
      "\n",
      "\n",
      "---- Test data ----\n",
      "Accuracy: 93.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3338\n",
      "           1       0.41      0.42      0.42       211\n",
      "           2       0.42      0.70      0.53       410\n",
      "           3       0.96      0.91      0.94      4932\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      8891\n",
      "   macro avg       0.69      0.75      0.71      8891\n",
      "weighted avg       0.93      0.91      0.92      8891\n",
      " samples avg       0.91      0.91      0.91      8891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "def train_and_evaluate(X_train, Y_train, X_test, Y_test):\n",
    "    global accuracyNN\n",
    "    m=X_train.shape[0]\n",
    "    n=X_train.shape[1]\n",
    "    classes=4\n",
    "    # Create layers\n",
    "    inputs = keras.layers.Input(shape=(n,), dtype='float32', name='input_layer') # Input (2 dimensions)\n",
    "    outputs = keras.layers.Dense(32, activation='tanh', name='hidden_layer1')(inputs) # Hidden layer\n",
    "    outputs = keras.layers.Dense(32, activation='tanh', name='hidden_layer2')(outputs) # Hidden layer\n",
    "    outputs = keras.layers.Dense(classes, activation='softmax', name='output_layer')(outputs) # Output layer \n",
    "    # Create a model from input layer and output layers\n",
    "    model = keras.models.Model(inputs=inputs, outputs=outputs, name='neural_network')\n",
    "    # Convert labels to categorical: categorical_crossentropy expects targets to be binary matrices (1s and 0s) of shape (samples, classes)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    Y_binary = keras.utils.to_categorical(Y_train, num_classes=classes, dtype='int')\n",
    "    # Train the model on the train set (output debug information)\n",
    "    model.fit(X_train, Y_binary, epochs=100, verbose=1)\n",
    "    # Save the model (Make sure that the folder exists)\n",
    "    model.save('nn.h5')\n",
    "    # Evaluate on training data\n",
    "    print('\\n-- Training data --')\n",
    "    predictions = model.predict(X_train)\n",
    "    #now make the prob. of the class which has the highest prob. as 1 and the prob. of other classes as 0\n",
    "    for i in range(m):\n",
    "      max=predictions[i].max()\n",
    "      predictions[i][predictions[i] != max]=0\n",
    "      predictions[i][predictions[i] == max]=1\n",
    "    accuracy = sklearn.metrics.accuracy_score(Y_binary, predictions)\n",
    "    print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n",
    "    print('Classification Report:')\n",
    "    print(sklearn.metrics.classification_report(Y_binary, predictions))\n",
    "    print('')\n",
    "    # Evaluate on test data\n",
    "    print('\\n---- Test data ----')\n",
    "    predictions = model.predict(X_test)\n",
    "    Y_test=np.asarray(Y_test).astype('int32')\n",
    "    Y_binary_test = keras.utils.to_categorical(Y_test, num_classes=classes, dtype='int')\n",
    "    m1=Y_test.shape[0]\n",
    "    for i in range(m1):\n",
    "      max=predictions[i].max()\n",
    "      predictions[i][predictions[i] != max]=0\n",
    "      predictions[i][predictions[i] == max]=1\n",
    "    accuracyNN = sklearn.metrics.accuracy_score(Y_binary_test, predictions)\n",
    "    print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n",
    "    print('Classification Report:')\n",
    "    print(sklearn.metrics.classification_report(Y_binary_test,predictions))\n",
    "\n",
    "# The main entry point for this module\n",
    "def main():\n",
    "    # Load data set (includes header values)\n",
    "    X_train_label,Y_train_label,X_test,Y_test=readDataMulti()\n",
    "    # Train and evaluate\n",
    "    train_and_evaluate(X_train_label, Y_train_label, X_test, Y_test)\n",
    "# Tell python to run main method\n",
    "if __name__ == \"__main__\": \n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-texas",
   "metadata": {
    "papermill": {
     "duration": 0.843611,
     "end_time": "2021-04-23T17:01:11.411992",
     "exception": false,
     "start_time": "2021-04-23T17:01:10.568381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building a Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-pacific",
   "metadata": {
    "papermill": {
     "duration": 0.892009,
     "end_time": "2021-04-23T17:01:13.142176",
     "exception": false,
     "start_time": "2021-04-23T17:01:12.250167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nearby-tsunami",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:14.832687Z",
     "iopub.status.busy": "2021-04-23T17:01:14.831811Z",
     "iopub.status.idle": "2021-04-23T17:01:15.216275Z",
     "shell.execute_reply": "2021-04-23T17:01:15.215732Z"
    },
    "papermill": {
     "duration": 1.233638,
     "end_time": "2021-04-23T17:01:15.216414",
     "exception": false,
     "start_time": "2021-04-23T17:01:13.982776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALLERGY': 0, 'COLD': 1, 'COVID': 2, 'FLU': 3}\n",
      "[[3241   81    2   14]\n",
      " [  82   73    6   50]\n",
      " [   3    5   42  360]\n",
      " [  22   67  343 4500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3338\n",
      "           1       0.32      0.35      0.33       211\n",
      "           2       0.11      0.10      0.10       410\n",
      "           3       0.91      0.91      0.91      4932\n",
      "\n",
      "    accuracy                           0.88      8891\n",
      "   macro avg       0.58      0.58      0.58      8891\n",
      "weighted avg       0.88      0.88      0.88      8891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_RF(X_train, y_train, X_test, y_test):\n",
    "  global accuracyRF\n",
    "  RFclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42) # 10 decision trees used in this classifier\n",
    "  RFclassifier.fit(X_train, y_train)  #training  \n",
    "  filename = 'rf_model.sav'\n",
    "  joblib.dump(RFclassifier, filename)  #save the model\n",
    "  y_pred = RFclassifier.predict(X_test) #predict on test set\n",
    "  accuracyRF = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "  print(sklearn.metrics.confusion_matrix(y_test,y_pred))\n",
    "  print(sklearn.metrics.classification_report(y_test,y_pred))\n",
    "\n",
    "def main():\n",
    "    X_train,Y_train,X_test,Y_test=readDataMulti()\n",
    "    train_and_evaluate_RF(X_train, Y_train, X_test, Y_test)\n",
    "# Tell python to run main method\n",
    "if __name__ == \"__main__\": \n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-questionnaire",
   "metadata": {
    "papermill": {
     "duration": 0.870854,
     "end_time": "2021-04-23T17:01:16.924467",
     "exception": false,
     "start_time": "2021-04-23T17:01:16.053613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building an SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-promotion",
   "metadata": {
    "papermill": {
     "duration": 0.83897,
     "end_time": "2021-04-23T17:01:18.693284",
     "exception": false,
     "start_time": "2021-04-23T17:01:17.854314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis.  An SVM maps training examples to points in space so as to maximise the width of the gap between the two categories. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "better-overview",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:20.384395Z",
     "iopub.status.busy": "2021-04-23T17:01:20.383697Z",
     "iopub.status.idle": "2021-04-23T17:01:40.600235Z",
     "shell.execute_reply": "2021-04-23T17:01:40.599655Z"
    },
    "papermill": {
     "duration": 21.069126,
     "end_time": "2021-04-23T17:01:40.600383",
     "exception": false,
     "start_time": "2021-04-23T17:01:19.531257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALLERGY': 0, 'COLD': 1, 'COVID': 2, 'FLU': 3}\n",
      "[[3317   18    3    0]\n",
      " [ 104   99    8    0]\n",
      " [   5    0  195  210]\n",
      " [  40   51  280 4561]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      3338\n",
      "           1       0.59      0.47      0.52       211\n",
      "           2       0.40      0.48      0.44       410\n",
      "           3       0.96      0.92      0.94      4932\n",
      "\n",
      "    accuracy                           0.92      8891\n",
      "   macro avg       0.73      0.72      0.72      8891\n",
      "weighted avg       0.92      0.92      0.92      8891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "def train_and_evaluate_SVM(X_train, y_train, X_test, y_test):\n",
    "  global accuracySVM\n",
    "  svclassifier = SVC(kernel='rbf')\n",
    "  svclassifier.fit(X_train, y_train)\n",
    "  filename = 'svm_model.sav'\n",
    "  joblib.dump(svclassifier, filename) #save the model\n",
    "  y_pred = svclassifier.predict(X_test)  #predict on test set\n",
    "  accuracySVM = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "  print(sklearn.metrics.confusion_matrix(y_test,y_pred))\n",
    "  print(sklearn.metrics.classification_report(y_test,y_pred))\n",
    "\n",
    "def main():\n",
    "    X_train,Y_train,X_test,Y_test=readDataMulti()\n",
    "    train_and_evaluate_SVM(X_train, Y_train, X_test, Y_test)\n",
    "# Tell python to run main method\n",
    "if __name__ == \"__main__\": \n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-parking",
   "metadata": {
    "papermill": {
     "duration": 0.851753,
     "end_time": "2021-04-23T17:01:42.337335",
     "exception": false,
     "start_time": "2021-04-23T17:01:41.485582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Testing on a single independent test instance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-chorus",
   "metadata": {
    "papermill": {
     "duration": 0.864896,
     "end_time": "2021-04-23T17:01:44.041504",
     "exception": false,
     "start_time": "2021-04-23T17:01:43.176608",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "productive-triumph",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:45.739547Z",
     "iopub.status.busy": "2021-04-23T17:01:45.738684Z",
     "iopub.status.idle": "2021-04-23T17:01:46.107964Z",
     "shell.execute_reply": "2021-04-23T17:01:46.107392Z"
    },
    "papermill": {
     "duration": 1.231366,
     "end_time": "2021-04-23T17:01:46.108130",
     "exception": false,
     "start_time": "2021-04-23T17:01:44.876764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you have  COUGH ?? Enter 1 for Yes and 0 for No-\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4c5de67b818e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Do you have \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"?? Enter 1 for Yes and 0 for No-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             raise StdinNotImplementedError(\n\u001b[0;32m--> 846\u001b[0;31m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m             )\n\u001b[1;32m    848\u001b[0m         return self._input_request(str(prompt),\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "# It can be used to reconstruct the model identically.\n",
    "n=colnames.shape[0]-1\n",
    "test_input=[]\n",
    "for i in range(n):\n",
    "    print(\"Do you have \", colnames[i], \"?? Enter 1 for Yes and 0 for No-\")\n",
    "    inp=input()\n",
    "    test_input.append(inp)\n",
    "test_input=np.asarray(test_input)\n",
    "test_input = test_input.reshape(1, -1)  #reshaping because right now shape of array is (n,) which has to be converted to (1,n)\n",
    "test_input = scaler.transform(test_input)\n",
    "key_list = list(dictionary.keys()) #make a list of keys \n",
    "val_list = list(dictionary.values()) #make a list of values \n",
    "\n",
    "# load the Neural Network model from disk\n",
    "nn_model = keras.models.load_model(\"nn.h5\")\n",
    "\n",
    "prediction1=nn_model(test_input) \n",
    "prediction1=np.asarray(prediction1)\n",
    "max_index_col = np.argmax(prediction1, axis=1) #find the max value in the output vector\n",
    "print(\"NN says you have\", key_list[val_list.index(max_index_col)]) #printing the key value wrt the output given by NN\n",
    "\n",
    "# load the Log. Reg. model from disk\n",
    "rf_model = joblib.load('rf_model.sav')\n",
    "prediction2=rf_model.predict(test_input)\n",
    "print(\"RF says you have\", key_list[val_list.index(prediction2)]) #printing the key value wrt the output given by NN\n",
    "# load the SVM model from disk\n",
    "svm_model = joblib.load('svm_model.sav')\n",
    "prediction3=svm_model.predict(test_input)\n",
    "print(\"SVM says you have\", key_list[val_list.index(prediction3)]) #printing the key value wrt the output given by NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-valuable",
   "metadata": {
    "papermill": {
     "duration": 0.846512,
     "end_time": "2021-04-23T17:01:47.798451",
     "exception": false,
     "start_time": "2021-04-23T17:01:46.951939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Plotting the performance of all the 3 classifiers on our dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "burning-mother",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T17:01:49.583996Z",
     "iopub.status.busy": "2021-04-23T17:01:49.583201Z",
     "iopub.status.idle": "2021-04-23T17:01:49.732094Z",
     "shell.execute_reply": "2021-04-23T17:01:49.731403Z"
    },
    "papermill": {
     "duration": 1.036021,
     "end_time": "2021-04-23T17:01:49.732310",
     "exception": false,
     "start_time": "2021-04-23T17:01:48.696289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.array([accuracyNN,accuracySVM,accuracyRF]) \n",
    "x = ['Neural Network','SVM','Random Forest']\n",
    "plt.bar(x,y)\n",
    "plt.title('Performance comparison')\n",
    "plt.xlabel('Classifiers')\n",
    "plt.ylabel('accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 193.197044,
   "end_time": "2021-04-23T17:01:52.017312",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-23T16:58:38.820268",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
